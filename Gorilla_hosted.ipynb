{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cybersoulja/1stastic/blob/steppingout/Gorilla_hosted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gorilla Hosted - Try it out in less than 60s üöÄ\n",
        "\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ShishirPatil/gorilla)  [![arXiv](https://img.shields.io/badge/arXiv-2305.15334-<COLOR>.svg?style=flat-square)](https://arxiv.org/abs/2305.15334)   [![Discord](https://img.shields.io/discord/1111172801899012102?label=Discord&logo=discord&logoColor=green&style=flat-square)](https://discord.gg/3apqwwME)  [![Twitter](https://img.shields.io/twitter/url?url=https://twitter.com/shishirpatil_/status/1661780076277678082)](https://twitter.com/shishirpatil_/status/1661780076277678082)\n",
        "\n",
        "Play around with Gorilla! Here, we host the Gorilla zero-shot models, so you can try it out! This is compatible with the OpenAI chat completion API - plug and play!\n",
        "\n",
        "We are happy to launch all three models: `gorilla-7b-hf-v0` which chooses from 925 Hugging Face APIs 0-shot, `gorilla-7b-th-v0` for 94 (exhaustive) Tensor Hub APIs 0-shot, `gorilla-7b-tf-v0` for 626 (exhaustive) Tensorflow Hub APIs 0-shot. In spirit of openess, we do not filter, nor carry out any post processing either to the prompt nor response. We will release the combined {HF+TF+TH} model which also has generic chat capability slowly to accomodate server demand.\n",
        "\n",
        "üíÉ If you want to use Gorilla or build on top of it! Feel absolutely free to do so - we believe in open source research and you don't even have to tell us! In case you choose to do, we have a vibrant community in Discord! Stop by and say Hi üëã\n",
        "\n",
        "<img src=\"https://github.com/ShishirPatil/gorilla/blob/gh-pages/assets/img/logo.png?raw=true\" width=30% height=30%>"
      ],
      "metadata": {
        "id": "7bKku43frr8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gorilla ü¶ç is hosted by UC Berkeley Sky lab for FREE ü§© as a research prototype ü§ì\n",
        "## Please don't spam the system or use it for commercial serving üëÄ"
      ],
      "metadata": {
        "id": "5PA9GQbV4rcN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBd_fso7qFPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d976a6e4-5d07-496d-bdfa-dba26b2738a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# Import Chat completion template and set-up variables\n",
        "!pip install openai\n",
        "import openai\n",
        "import urllib.parse\n",
        "\n",
        "openai.api_key = \"EMPTY\" # Key is ignored and does not matter\n",
        "openai.api_base = \"http://34.132.127.197:8000/v1\"\n",
        "\n",
        "# Report issues\n",
        "def raise_issue(e, model, prompt):\n",
        "    issue_title = urllib.parse.quote(\"[bug] Hosted Gorilla: <Issue>\")\n",
        "    issue_body = urllib.parse.quote(f\"Exception: {e}\\nFailed model: {model}, for prompt: {prompt}\")\n",
        "    issue_url = f\"https://github.com/ShishirPatil/gorilla/issues/new?assignees=&labels=hosted-gorilla&projects=&template=hosted-gorilla-.md&title={issue_title}&body={issue_body}\"\n",
        "    print(f\"An exception has occurred: {e} \\nPlease raise an issue here: {issue_url}\")\n",
        "\n",
        "# Query Gorilla server \n",
        "def get_gorilla_response(prompt=\"I would like to translate from English to French.\", model=\"gorilla-7b-hf-v0\"):\n",
        "  try:\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=model,\n",
        "      messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "  except Exception as e:\n",
        "    raise_issue(e, model, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Translation ‚úç with ü§ó"
      ],
      "metadata": {
        "id": "asdPNq38qIx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I would like to translate from English to Chinese.\"\n",
        "print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v0\" ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMnJzPaN5FlV",
        "outputId": "464ae4f8-0ca2-4414-9cbb-28ed0644eddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<domain>>>: Natural Language Processing Translation\n",
            "<<<api_call>>>: AutoModelForSeq2SeqLM.from_pretrained('Helsinki-NLP/opus-mt-en-zh')\n",
            "<<<api_provider>>>: Hugging Face Transformers\n",
            "<<<explanation>>>: 1. Import the necessary classes from the transformers library, which are AutoTokenizer and AutoModelForSeq2SeqLM.\n",
            "2. Use the from_pretrained method of the AutoTokenizer class to load the tokenizer of the model 'Helsinki-NLP/opus-mt-en-zh'.\n",
            "3. Use the from_pretrained method of the AutoModelForSeq2SeqLM class to load the pre-trained translation model 'Helsinki-NLP/opus-mt-en-zh'. This model is trained to translate English text to Chinese.\n",
            "4. You can now use this model to translate any given English text to Chinese using the tokenizer and the model together.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: Object detection üî∑ with ü§ó"
      ],
      "metadata": {
        "id": "Gnx7YHf18DTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"I want to build a robot that can detecting objects in an image.\"\n",
        "print(get_gorilla_response(prompt, model=\"gorilla-7b-hf-v0\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WochUPqf8HLa",
        "outputId": "b88b3cc6-89f0-4cd0-ddf4-7fc5b47c2097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<domain>>>: Computer Vision Object Detection\n",
            "<<<api_call>>>: YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
            "<<<api_provider>>>: Hugging Face Transformers\n",
            "<<<explanation>>>: 1. First, we import the necessary classes from the transformers package and PIL package for image processing. This includes YolosForObjectDetection for the object detection model and Image for processing image data.\n",
            "2. We then use the from_pretrained method of the YolosForObjectDetection class to load the pre-trained model 'hustvl/yolos-tiny'. This model has been trained for object detection tasks, which is what we need for detecting objects in an image.\n",
            "3. We load the image data from a file or a real-time feed from a camera.\n",
            "4. This model can then be used to analyze an image and identify the various objects in it.\n",
            "5. Once the objects in the image are detected, additional processing can be performed, if needed, to extract further information or take actions based on the detected objects.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's try to invoke APIs from Torch Hub and TensorFlow Hub instead for the same prompts!"
      ],
      "metadata": {
        "id": "Ot4EKOLXhpoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation ‚úç with Torch Hub\n",
        "prompt = \"I would like to translate from English to Chinese.\"\n",
        "print(get_gorilla_response(prompt, model=\"gorilla-7b-th-v0\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS-ZeP0rhmzp",
        "outputId": "ba112578-ffaa-417f-c6ab-10600a7a7406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'domain': 'Machine Translation', 'api_call': \\\"model = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr', tokenizer='moses', bpe='subword_nmt')\\\", 'api_provider': 'PyTorch', 'explanation': 'Load the pretrained Transformer model from PyTorch Hub to perform English-to-Chinese translation.', 'code': 'import torch\\ntokenizer = torch.hub.load('pytorch/fairseq', 'moses', pretrained=True)'}\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Object Detection üî∑ with Tensor Flow\n",
        "prompt = \"I want to build a robot that can detecting objects in an image.\"\n",
        "print(get_gorilla_response(prompt, model=\"gorilla-7b-tf-v0\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CF-4LAvhs2i",
        "outputId": "5f07f892-493f-4410-a32c-bd2e22f7fd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<<<domain>>>: Image object detection, <<<api_call>>>: hub.load('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'), <<<api_provider>>>: TensorFlow Hub, <<<explanation>>>: This API call loads the pre-trained SSD MobileNet V2 object detection model from TensorFlow Hub. The model can be used to detect multiple objects in an image. Once loaded, you can pass an image to the model, and it will return the detected objects along with their bounding boxes, class labels, and associated confidence scores. This is useful for building robots that can detect objects in their environment. <<<code>>>: import tensorflow as tf\\nimport tensorflow_hub as hub\\nmodel_id = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'\\ndetector = hub.load(model_id)\\nimage = tf.image.decode_jpeg(tf.io.read_file('path/to/image.jpg'))\\nimage = tf.image.resize(image, (300, 300))\\nimage = tf.expand_dims(image, axis=0)\\nresult = detector(image)\\nprint(result['detection_boxes'], result['detection_classes'], result['detection_scores'])\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ Using gorilla is as easy as calling `get_gorilla_response()` with your prompt! Try out Gorilla, and share your interesting findings in `#showcase` ü§© [Discord](https://discord.gg/3apqwwME)!"
      ],
      "metadata": {
        "id": "XS5Qe6zD8tdX"
      }
    }
  ]
}